{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data is misformatted\n",
    "\n",
    "Fix it by removing the \n",
    "\n",
    "```<?xml version=\"1.0\" encoding=\"utf-8\"?>```\n",
    "\n",
    "from every line and adding root.\n",
    "\n",
    "We go from __01_fill_output_cleaned.xml__ to __02_data.xml__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "raw_file = codecs.open(data_folder + '01_full_output_cleaned.xml', 'rU', 'utf-8')\n",
    "cleaned_file = codecs.open(data_folder + '02_data.xml', 'w', 'utf-8')\n",
    "cleaned_file.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<root>\\n')\n",
    "for i in raw_file:\n",
    "    if i[:4]!='<?xm':\n",
    "        cleaned_file.write(i)\n",
    "cleaned_file.write('</root>')\n",
    "cleaned_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test dataset for testing parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "raw_file = codecs.open(data_folder + '01_full_output_cleaned.xml', 'rU', 'utf-8')\n",
    "cleaned_file = codecs.open(data_folder + '02_data_test.xml', 'w', 'utf-8')\n",
    "cleaned_file.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<root>\\n')\n",
    "for i, l in enumerate(raw_file):\n",
    "    if i < 1000:\n",
    "        if l[:4]!='<?xm':\n",
    "            cleaned_file.write(l)\n",
    "cleaned_file.write('</root>')\n",
    "cleaned_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the XML to get client - agent messages\n",
    "\n",
    "Get touples of client-agent conversation bits from XML formatted chats. This will produce __03_clientMessages.txt__ and __03_agentMessages.txt__.\n",
    "\n",
    "Also save the length of coversation and ID of conversation in __03_convLen.txt__ and __03_convNum.txt__, plus weather an external agent (customer service guy who has more specific knowledge about the customer's problem) took over the conversation from the original agent (saved to __03_externalAgent.txt__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # xml parsing library\n",
    "\n",
    "# open files\n",
    "client_messages_file = codecs.open(data_folder + '03_clientMessages.txt', 'a', 'utf-8')\n",
    "agent_messages_file = codecs.open(data_folder + '03_agentMessages.txt', 'a', 'utf-8')\n",
    "conversation_num_file = codecs.open(data_folder + '03_convNum.txt', 'a', 'utf-8')\n",
    "conversation_len_file = codecs.open(data_folder + '03_convLen.txt', 'a', 'utf-8')\n",
    "external_agent_file = codecs.open(data_folder + '03_externalAgent.txt', 'a', 'utf-8')\n",
    "cleaned_file = codecs.open(data_folder + '02_data_test.xml', 'rU', 'utf-8')\n",
    "\n",
    "conversation_num = 0\n",
    "\n",
    "for i, line in enumerate(cleaned_file):\n",
    "    # ignore xml declaration and root line\n",
    "    if i > 1:\n",
    "        # define each line as a new xml object\n",
    "        chat = BeautifulSoup(line, 'xml')\n",
    "        \n",
    "        # define main variables\n",
    "        parties = chat.findAll('newParty')\n",
    "        messagePairs = []\n",
    "        clientID = ''\n",
    "        agentID = ''\n",
    "        externalID = ''\n",
    "        \n",
    "        # work out which message belongs to whom: client, agent\n",
    "        for party in parties:\n",
    "            if party.userInfo['userType'] == 'CLIENT':\n",
    "                clientID = party['userId']\n",
    "            elif party.userInfo['userType'] == 'AGENT':\n",
    "                agentID = party['userId']\n",
    "            elif party.userInfo['userType'] == 'EXTERNAL':\n",
    "                externalID = party['userId']\n",
    "                \n",
    "        # get all messages from the chat\n",
    "        messages = chat.findAll('message')\n",
    "        \n",
    "        # define flags for merging consequtive messages from the same party\n",
    "        first_client_message = 0\n",
    "        client_message = 0\n",
    "        agent_message = 0\n",
    "        \n",
    "        # do we have both client and agent?        \n",
    "        for message in messages:\n",
    "            # we look for the first client message and start with that\n",
    "            if message['userId'] == clientID and first_client_message == 0:\n",
    "                first_client_message = 1\n",
    "                client_message =  1\n",
    "                client_message_text = message.msgText.contents[0]\n",
    "            \n",
    "            # CLIENT MESSAGE\n",
    "            if message['userId'] == clientID and first_client_message == 1:\n",
    "                # if the agent has spoken and now it's client again, save previous touple            \n",
    "                if agent_message == 1:\n",
    "                    messagePairs.append((client_message_text, agent_message_text))\n",
    "                    agent_message = 0\n",
    "                \n",
    "                # if no previous client message define new client_message_text\n",
    "                if client_message == 0:\n",
    "                    client_message_text = message.msgText.contents[0]\n",
    "                # else continue previous\n",
    "                elif client_message == 1 and message.msgText.contents[0] != client_message_text:\n",
    "                    client_message_text += ' ' + message.msgText.contents[0]\n",
    "                client_message = 1\n",
    "                \n",
    "            # AGENT MASSAGE\n",
    "            if (message['userId'] == agentID or message['userId'] == externalID) and first_client_message == 1:\n",
    "                client_message = 0\n",
    "                # if no previous agent message define new client_message_text\n",
    "                if agent_message == 0:                \n",
    "                    agent_message_text = message.msgText.contents[0]\n",
    "                # else continue previous\n",
    "                else:\n",
    "                    agent_message_text += ' ' + message.msgText.contents[0]\n",
    "                agent_message = 1\n",
    "                \n",
    "        # if the very last touple wasn't saved save it\n",
    "        if agent_message == 1:\n",
    "            messagePairs.append((client_message_text, agent_message_text))\n",
    "            \n",
    "        # write out sentences from conversation\n",
    "        if len(messagePairs) != 0:\n",
    "            for m in messagePairs:\n",
    "                \n",
    "                client_messages_file.write(m[0] + '\\n')\n",
    "                agent_messages_file.write(m[1] + '\\n')\n",
    "            conversation_num_file.write('\\n'+'\\n'.join([str(conversation_num)] * len(messagePairs)))\n",
    "            conversation_len_file.write('\\n'+'\\n'.join([str(len(messagePairs))] * len(messagePairs)))\n",
    "            if externalID == '':\n",
    "                external_agent_file.write('\\n'+'\\n'.join(['0'] * len(messagePairs)))    \n",
    "            else:\n",
    "                external_agent_file.write('\\n'+'\\n'.join(['1'] * len(messagePairs)))    \n",
    "            conversation_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the length of conversations\n",
    "\n",
    "Check the distribution of length of conversations. The x-axis represent question answer tuples, so 10 means a conversation with 20 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x7efe3c3afc50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAFzCAYAAABy9g57AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSJEkq4f8BDgTfsekzH+MAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as  plt\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "f = open(data_folder + '03_convNum.txt')\n",
    "conv_num =[]\n",
    "for i, line in enumerate(f):\n",
    "    if i > 0:\n",
    "        conv_num.append(int(line.strip()))\n",
    "        \n",
    "f = open(data_folder + '03_convLen.txt')\n",
    "conv_len =[]\n",
    "for i, line in enumerate(f):\n",
    "    if i > 0:\n",
    "        conv_len.append(int(line.strip()))\n",
    "\n",
    "df = pd.DataFrame(zip(conv_num, conv_len), columns = ['ID', 'length'])\n",
    "len_of_convs = df.groupby('ID')['length'].mean()\n",
    "len_of_convs.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords\n",
    "\n",
    "Remove stopwords and punctuation from both client and agent messages, and create concatened message corpus, where each line has a question from the client and an answer from the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import izip\n",
    "\n",
    "# load stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "# regexp for removing punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# open files for filtering\n",
    "client_messages = codecs.open(data_folder + '03_clientMessages.txt', 'rU', 'utf-8')\n",
    "client_messages2 = codecs.open(data_folder + '03_clientMessagesMatch04.txt', 'w', 'utf-8')\n",
    "client_messages_filtered = codecs.open(data_folder + '04_clientMessagesFiltered.txt', 'w', 'utf-8')\n",
    "agent_messages = codecs.open(data_folder + '03_agentMessages.txt', 'rU', 'utf-8')\n",
    "agent_messages2 = codecs.open(data_folder + '03_agentMessagesMatch04.txt', 'w', 'utf-8')\n",
    "agent_messages_filtered = codecs.open(data_folder + '04_agentMessagesFiltered.txt', 'w', 'utf-8')\n",
    "client_agent_messages_filtered = codecs.open(data_folder + '04_clientAgentMessagesFiltered.txt', 'w', 'utf-8')\n",
    "\n",
    "def join_line(line_list):\n",
    "    \"\"\"\n",
    "    Joins a list of strings into one string.\n",
    "    \"\"\"\n",
    "    return ' '.join(line_list)\n",
    "\n",
    "with client_messages as client, agent_messages as agent: \n",
    "    for client_line, agent_line in izip(client, agent):\n",
    "        no_punctuation_client = join_line(tokenizer.tokenize(client_line))\n",
    "        no_punctuation_agent = join_line(tokenizer.tokenize(agent_line))\n",
    "        \n",
    "        if len(no_punctuation_client) > 0 and len(no_punctuation_agent) > 0:\n",
    "            no_punctuation_client = no_punctuation_client.lower().split()\n",
    "            no_punctuation_agent = no_punctuation_agent.lower().split()\n",
    "            no_stopwords_client = [w for w in no_punctuation_client if w not in stop]\n",
    "            no_stopwords_agent = [w for w in no_punctuation_agent if w not in stop]\n",
    "\n",
    "            if len(no_stopwords_client) > 0 and len(no_stopwords_agent) > 0:\n",
    "                no_stopwords_client = join_line(no_stopwords_client)\n",
    "                no_stopwords_agent = join_line(no_stopwords_agent)\n",
    "                client_messages2.write(client_line)\n",
    "                agent_messages2.write(agent_line)\n",
    "                client_messages_filtered.write(no_stopwords_client + '\\n')\n",
    "                agent_messages_filtered.write(no_stopwords_agent + '\\n')\n",
    "                client_agent_messages_filtered.write(no_stopwords_client + ' ' + no_stopwords_agent + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge phrases of bigrams and trigrams\n",
    "\n",
    "Adapted from Walter's feature_extraction notebook. It will group together common phrases like thank you as thank_you.\n",
    "\n",
    "Creates __05_clientMessagesFiltered_trigram__, __05_agentMessagesFiltered_trigram__, __05_clientAgentMessagesFiltered_trigram__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim as gs\n",
    "files = [\"04_clientMessagesFiltered\", \"04_agentMessagesFiltered\", \"04_clientAgentMessagesFiltered\"]\n",
    "\n",
    "for f in files:\n",
    "    file_open = codecs.open(data_folder + f + '.txt','r','utf-8')\n",
    "    chats = []\n",
    "    for line in file_open:\n",
    "        chats.append(line.strip().split())\n",
    "        \n",
    "    # find collections \n",
    "    bigram = gs.models.Phrases(chats)\n",
    "    trigram = gs.models.Phrases(bigram[chats])\n",
    "    \n",
    "    \n",
    "    # write results\n",
    "    filename = f.split('_')[1]\n",
    "    outfile = codecs.open(data_folder + '05_' + filename  + \"_bigram.txt\", 'w', 'utf-8')\n",
    "    for sentence in list(bigram[chats]):\n",
    "        try:\n",
    "            outfile.write(\" \".join(sentence) + \"\\n\")\n",
    "        except:\n",
    "            pass\n",
    "    outfile = codecs.open(data_folder + '05_' + filename + \"_trigram.txt\", 'w', 'utf-8')\n",
    "    for sentence in list(trigram[chats]):\n",
    "        try:\n",
    "            outfile.write(\" \".join(sentence) + \"\\n\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate vectors for each sentence using the W2V models of Nico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gensim as gs\n",
    "# Load model\n",
    "model = gs.models.Word2Vec.load(os.path.join(data_folder, 'clientW2V_BothSeperate'))\n",
    "\n",
    "# Load client text and calculate average word vector\n",
    "client_file = codecs.open(data_folder + '04_clientMessagesFiltered.txt', 'r', 'utf-8')\n",
    "\n",
    "sentence_vects = []\n",
    "for i, sentence in enumerate(client_file):\n",
    "    sentence_matrix = np.array([model[w].T for w in sentence.strip().split() if w in model])\n",
    "    sentence_vect = np.mean(sentence_matrix, axis=0)\n",
    "    try:\n",
    "        sentence_vects.append(sentence_vect)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_sentences = np.zeros((len(sentence_vects), 100))\n",
    "for i, sentence in enumerate(sentence_vects):\n",
    "    client_sentences[i, :] = np.array(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train KD Tree, define lookup function, save  and load KD Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentence_vector(sentence):\n",
    "    sentence_matrix = np.array([model[w].T for w in sentence.strip().split() if w in model])\n",
    "    sentence_vect = np.mean(sentence_matrix, axis=0)\n",
    "    return sentence_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "tree = KDTree(client_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "# save the classifier\n",
    "with open(data_folder + 'kdtree.pkl', 'wb') as fid:\n",
    "    cPickle.dump(tree, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e6df6f3ae57a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# load it again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'kdtree.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: unsupported pickle protocol: 3"
     ]
    }
   ],
   "source": [
    "# load it again\n",
    "with open(data_folder + 'kdtree.pkl', 'rb') as fid:\n",
    "    tree = cPickle.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test preliminary model with query sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "query = 'i want to reschedule my delivery date'\n",
    "query = 'i think my order got lost'\n",
    "query = 'cannot log into my account'\n",
    "dist, ind = tree.query(get_sentence_vector(query), k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIENT:  I cannot log into my account \n",
      "\n",
      "AGENT:  i am sorry to hear that Elizabeth. Could you please tell me what error you are getting, when you are trying to login.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client_file = codecs.open(data_folder + '03_clientMessagesMatch04.txt', 'r', 'utf-8')\n",
    "agent_file = codecs.open(data_folder + '03_agentMessagesMatch04.txt', 'r', 'utf-8')\n",
    "for i, line in enumerate(client_file):\n",
    "    if i == ind[0][0]:\n",
    "        print 'CLIENT: ', line\n",
    "for i, line in enumerate(agent_file):\n",
    "    if i == ind[0][0]:\n",
    "        print 'AGENT: ', line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beta chatbot v. 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def lookup_answer(query):\n",
    "    try:\n",
    "        dist, ind = tree.query(get_sentence_vector(query.lower()), k=1)\n",
    "        agent_file = codecs.open(data_folder + '03_agentMessagesMatch04.txt', 'r', 'utf-8')\n",
    "        client_file = codecs.open(data_folder + '03_clientMessagesMatch04.txt', 'r', 'utf-8')\n",
    "        for i, line in enumerate(agent_file):\n",
    "            if i == ind[0][0]:\n",
    "                agent_line = line\n",
    "                break\n",
    "        for i, line in enumerate(client_file):\n",
    "            if i == ind[0][0]:\n",
    "                client_line = line\n",
    "                break\n",
    "    except:\n",
    "        agent_line = \"Oops that didn't work. Try something else..\"\n",
    "        client_line = ''\n",
    "            \n",
    "    return agent_line, client_line\n",
    "    \n",
    "def chatbot():\n",
    "    while True:\n",
    "        agent_line, client_line = lookup_answer(raw_input())\n",
    "        client_line = (\"(%s)\\n\" % client_line.strip())\n",
    "        print client_line, agent_line\n",
    "\n",
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
