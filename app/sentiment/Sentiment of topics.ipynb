{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis with Vader\n",
    "Calculate a sentiment for all chats in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from nltk.sentiment import vader\n",
    "\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "input_file = '03_doc2vecTrainingData.txt'\n",
    "input_file = codecs.open(os.path.join(data_folder, input_file), 'rU', 'utf-8')\n",
    "docs = []\n",
    "for line in input_file:\n",
    "    docs.append(line.strip())\n",
    "\n",
    "vaderize = vader.SentimentIntensityAnalyzer()\n",
    "# results = np.zeros((len(docs), 4))\n",
    "\n",
    "def get_sentiment(doc, i):\n",
    "    sentiment = vaderize.polarity_scores(doc)\n",
    "    result = np.zeros((1, 4))\n",
    "    result[0, 0] = sentiment['compound']\n",
    "    result[0, 1] = sentiment['neg']\n",
    "    result[0, 2] = sentiment['neu']\n",
    "    result[0, 3] = sentiment['pos']\n",
    "    return result\n",
    "\n",
    "results = np.array(Parallel(n_jobs=-1)(delayed(get_sentiment)(doc, i) for i, doc in enumerate(docs)))\n",
    "results = results.reshape((results.shape[0], 4))\n",
    "cols = ['Compound', 'Negative', 'Neutral', 'Positive']\n",
    "saveto = '~/s2ds/Data/sentiment.csv'\n",
    "pd.DataFrame(results, columns=cols).to_csv(saveto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment for each client and agent sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from nltk.sentiment import vader\n",
    "\n",
    "input_files = ['03_clientMessages.txt', '03_agentMessages.txt']\n",
    "save_tos = ['~/s2ds/Data/sentiment_client.csv', '~/s2ds/Data/sentiment_agent.csv']\n",
    "\n",
    "for file_i, input_file in enumerate(input_files):\n",
    "    data_folder = '/home/daniel/s2ds/Data/'\n",
    "    input_file = codecs.open(os.path.join(data_folder, input_file), 'rU', 'utf-8')\n",
    "    docs = []\n",
    "    for line in input_file:\n",
    "        docs.append(line.strip())\n",
    "\n",
    "    vaderize = vader.SentimentIntensityAnalyzer()\n",
    "    # results = np.zeros((len(docs), 4))\n",
    "\n",
    "    def get_sentiment(doc, i):\n",
    "        sentiment = vaderize.polarity_scores(doc)\n",
    "        result = np.zeros((1, 4))\n",
    "        result[0, 0] = sentiment['compound']\n",
    "        result[0, 1] = sentiment['neg']\n",
    "        result[0, 2] = sentiment['neu']\n",
    "        result[0, 3] = sentiment['pos']\n",
    "        return result\n",
    "\n",
    "    results = np.array(Parallel(n_jobs=-1)(delayed(get_sentiment)(doc, i) for i, doc in enumerate(docs)))\n",
    "    results = results.reshape((results.shape[0], 4))\n",
    "    cols = ['Compound', 'Negative', 'Neutral', 'Positive']\n",
    "    save_to = save_tos[file_i]\n",
    "    pd.DataFrame(results, columns=cols).to_csv(saveto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then these two files were merged into one, with the convID column from the client_agent_summary2.csv, which resulted in the client_agent_sentiment.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Spearman rho through the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def delayed_spearman(df, min_num=10):\n",
    "    \"\"\"\n",
    "    Calculates the Spearman correlation between a +1 delayed pairs of\n",
    "    sentiment  values. I.e. it connects the first agent sentiment value\n",
    "    with the 2nd of the client, and the 2nd agent with the 3rd client,\n",
    "    etc. If there isn't enough (min_num) pairs, it returns None.\n",
    "    \n",
    "    :param df [pandas DataFrame], holding sentiment for each message for\n",
    "               a whole conversation, with agent and client columns.\n",
    "    :param min_num [int], the minimum number of sentiment value pairs \n",
    "                    that are needed to calculate a Spearman coef.\n",
    "    :return Spearman correlation coefficient.\n",
    "    \"\"\"\n",
    "    n, p = df.shape\n",
    "    # shift client column up by one index (discarding first cell in it)\n",
    "    client = df.client.values\n",
    "    agent = df.agent.values\n",
    "    client[0:n-1] = client[1:n]\n",
    "    client = client[:n-1]\n",
    "    agent = agent[:n-1]\n",
    "    if client.shape[0] < min_num:\n",
    "        return None\n",
    "    else:\n",
    "        return stats.spearmanr(agent, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates Spearman rho in parallel, for each conversation which has at least 10 messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sentiment = pd.read_csv('/home/daniel/s2ds/Data/sentiment_client_agent.csv', index_col=0)\n",
    "conv_num = sentiment.convID.max() + 1\n",
    "results = np.zeros((conv_num, 2))\n",
    "\n",
    "def spearman_wrapper(i, sentiment):\n",
    "    chat = sentiment[sentiment.convID==i][['agent','client']]\n",
    "    result =  delayed_spearman(chat)\n",
    "    if result is not None:\n",
    "        return np.array([result[0], result[1]])\n",
    "    else:\n",
    "        return np.array([0, 1])\n",
    "\n",
    "results = np.array(Parallel(n_jobs=-1)(delayed(spearman_wrapper)(i, sentiment) for i in xrange(conv_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = pd.DataFrame(results, columns=['rho', 'p-val'])\n",
    "r.to_csv('/home/daniel/s2ds/Data/sentiment_client_agent_spearman.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot conversations with significant p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "# setup the plot\n",
    "sns.set_context('poster', font_scale=1.5)\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# find conversations with significant correlations between agent and client sentiment\n",
    "sentiment = pd.read_csv('/home/daniel/s2ds/Data/sentiment_client_agent.csv', index_col=0)\n",
    "results = pd.read_csv('/home/daniel/s2ds/Data/sentiment_client_agent_spearman.csv', index_col=0).values\n",
    "significant = np.where(results[:,1] < .05)[0]\n",
    "for i, ID in enumerate(significant):\n",
    "    # build title of figure\n",
    "    r = \"{0:.2f}\".format(results[ID, 0])\n",
    "    p = \"{0:.2f}\".format(results[ID, 1])\n",
    "    t = \"Rho: %s, p-val: %s\" % (r, p)\n",
    "    # get sentiment values for the conversation\n",
    "    df = sentiment[sentiment.convID==ID][['agent','client']]\n",
    "    df.index = range(df.shape[0])\n",
    "    # shift the client values up as done in delayed_spearman\n",
    "    n, p = df.shape\n",
    "    df.client[0:n-1] = df.client[1:n]\n",
    "    df = df[:n-1]\n",
    "    # plot and save\n",
    "    ax = df.plot(title=t)\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('/home/daniel/Desktop/sentiment/conversation' + str(ID) + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check an actual conversation corresponding to one of these images run the  following with one of conversation ID's as line numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script bash\n",
    "cd ~/s2ds/Data/\n",
    "sed -n 3079,3079p 03_doc2vecTrainingData.txt | xsel -b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot boxplots by level in conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment = pd.read_csv('/home/daniel/s2ds/Data/sentiment_client_agent.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "# setup the plot\n",
    "sns.set_context('talk', font_scale=1.5)\n",
    "#plt.figure(figsize=(20, 16))\n",
    "\n",
    "sentiment = pd.read_csv('/home/daniel/s2ds/Data/sentiment_client_agent.csv', index_col=0)\n",
    "# discard very long conversations\n",
    "sentiment = sentiment[sentiment.convPos<21]\n",
    "sentiment = sentiment[['agent','client', 'convPos', 'convID', 'convLen']]\n",
    "mu = sentiment.groupby('convPos').mean()\n",
    "sd = sentiment.groupby('convPos').std()\n",
    "count = sentiment.groupby('convPos').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oldschool ploting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths = mu.shape[0] + 1\n",
    "plt.figure()\n",
    "plt.errorbar(range(1, lengths), mu.agent, yerr=sd.agent.values/np.sqrt(count.agent))\n",
    "plt.title(\"Average agent sentiment of 51000 conversations\")\n",
    "plt.xlabel(\"Line of conversation\")\n",
    "plt.ylabel(\"Sentiment: negative (-1) to positive (+1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fancier plots with sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quick reshufffle of the data for the sns plot, only use a subsample of 1000\n",
    "#s = sentiment.iloc[np.random.choice(xrange(sentiment.shape[0]),size=1000,replace=False), :]\n",
    "s = sentiment\n",
    "a = s[['agent', 'client']].stack(0)\n",
    "a = a.reset_index([1])\n",
    "a.columns = ['actor', 'sentiment']\n",
    "df = a.join(s[['convPos', 'convID', 'convLen']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can only plot conversations of a given length\n",
    "%matplotlib qt\n",
    "length = 10\n",
    "df = df[df.convLen == length]\n",
    "sns.tsplot(data=df, time=\"convPos\", unit=\"convID\", condition=\"actor\", value=\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = sns.regplot(x=\"convPos\", y=\"sentiment\", data=df, x_estimator=np.mean, logx=True, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# Load the example titanic dataset\n",
    "\n",
    "# Make a custom palette with gendered colors\n",
    "pal = dict(agent=\"#6495ED\", client=\"#F08080\")\n",
    "\n",
    "# Show the survival proability as a function of age and sex\n",
    "g = sns.lmplot(x=\"convPos\", y=\"sentiment\", col=\"actor\", hue=\"actor\", data=df,\n",
    "               palette=pal, y_jitter=.02)\n",
    "g.set(xlim=(0, 80), ylim=(-.05, 1.05))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
