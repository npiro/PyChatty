{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean original XML file\n",
    "\n",
    "The original file is misformatted, let's clean that up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing.clean_original_xml import clean_original_xml\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "raw_file = '01_full_output_cleaned.xml'\n",
    "cleaned_file = '02_data.xml'\n",
    "clean_original_xml(data_folder, raw_file, cleaned_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get client agent messages and full conversations\n",
    "This part extract paired client-agent messages and full conversations (training data for Doc2Vec) as well, for more see docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import preprocessing.xml_parsing as xp\n",
    "reload(xp)\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "input_file = '02_data.xml'\n",
    "# input_file = '02_data_test.xml'\n",
    "client_messages_file = '03_clientMessages.txt'\n",
    "agent_messages_file = '03_agentMessages.txt'\n",
    "conv_messages_file = '03_doc2vecTrainingData.txt'\n",
    "xp.get_client_agent_conversations(data_folder, input_file, client_messages_file, \n",
    "                                  agent_messages_file, conv_messages_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training data for Word2Vec\n",
    "This part is written so we can maximise the amount of training data we have for the Word2Vec model. See docs for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import preprocessing.xml_parsing as xp\n",
    "reload(xp)\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "input_file = '02_data.xml'\n",
    "# input_file = '02_data_test.xml'\n",
    "output_file = '03_word2vecTrainingData.txt'\n",
    "xp.get_w2v_training(data_folder, input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some quick line counting for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script bash \n",
    "cd ~/s2ds/Data/\n",
    "wc -l 03_clientMessages.txt\n",
    "wc -l 03_agentMessages.txt\n",
    "wc -l 03_doc2vecTrainingData.txt\n",
    "wc -l 03_doc2vecTrainingData2.txt\n",
    "wc -l 03_word2vecTrainingData.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter word2vecTrainingData\n",
    "Get rid of punctuation, names, emails postcodes, numbers, etc.. lot's going on, check documentation.\n",
    "\n",
    "no n_grams, no lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd ~/ms/Daniel/\n",
    "import preprocessing.filtering as filtering\n",
    "reload(filtering)\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "input_file = '03_word2vecTrainingData.txt'\n",
    "output_file = '04_word2vecTrainingDataFiltered.txt'\n",
    "\n",
    "names = filtering.build_names(data_folder)\n",
    "# word_cache is a dict with lemmatized values\n",
    "word_cache = filtering.filter_corpus(data_folder, input_file, output_file, preprocessing=True, spellcheck=True,\n",
    "                                     names=names, lemmatize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter doc2vecTrainingData2\n",
    "\n",
    "no n_grams, no lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ~/ms/Daniel/\n",
    "import preprocessing.filtering as filtering\n",
    "reload(filtering)\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "input_file = '03_doc2vecTrainingData2.txt'\n",
    "output_file = '04_doc2vecTrainingDataFiltered2.txt'\n",
    "\n",
    "names = filtering.build_names(data_folder)\n",
    "# word_cache is a dict with lemmatized values\n",
    "filtering.filter_corpus(data_folder, input_file, output_file, preprocessing=True, spellcheck=True,\n",
    "                        names=names, lemmatize=False, nltk_preproc=word_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make doc2vecTraingingData from  doc2vecTraingingData2\n",
    "Just remove all ||."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs, os\n",
    "import preprocessing.filtering as filtering\n",
    "reload(filtering)\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "input_file = '04_doc2vecTrainingDataFiltered2.txt'\n",
    "output_file = '04_doc2vecTrainingDataFiltered.txt'\n",
    "input_file = codecs.open(os.path.join(data_folder, input_file), 'rU', 'utf-8')\n",
    "output_file = codecs.open(os.path.join(data_folder, output_file), 'w', 'utf-8')\n",
    "for i, line in enumerate(input_file):\n",
    "    output_file.write(line.replace('||', ''))\n",
    "    # close files\n",
    "input_file.close()\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter client-agent message pairs\n",
    "no n_grams, no lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ~/ms/Daniel/\n",
    "import preprocessing.filtering as filtering\n",
    "reload(filtering)\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "client_file = '03_clientMessages.txt'\n",
    "client_output = '04_clientMessagesFiltered.txt'\n",
    "agent_file = '03_agentMessages.txt'\n",
    "agent_output = '04_agentMessagesFiltered.txt'\n",
    "\n",
    "names = filtering.build_names(data_folder)\n",
    "filtering.filter_client_agent(data_folder, client_file, agent_file, client_output,\n",
    "                              agent_output, preprocessing=True, spellcheck=True, names=names, lemmatize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run client_agent_conv, to get a one2one correspondance between client messages and convNum for fastText training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/Dropbox/S2DS/Code/Daniel\n"
     ]
    }
   ],
   "source": [
    "%cd ~/ms/Daniel/\n",
    "import preprocessing.filtering as filtering\n",
    "reload(filtering)\n",
    "data_folder = '/home/daniel/s2ds/Data/'\n",
    "client_file = '03_clientMessages.txt'\n",
    "client_output = '05_clientMessagesFilteredfastText.txt'\n",
    "agent_file = '03_agentMessages.txt'\n",
    "agent_output = '05_agentMessagesFilteredfastText.txt'\n",
    "conv_output = '05_fastTextConv.txt'\n",
    "names = filtering.build_names(data_folder)\n",
    "filtering.filter_client_agent_conv(data_folder, client_file, agent_file, client_output, agent_output, \n",
    "                              conv_output, preprocessing=True, spellcheck=True, names=names, lemmatize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check file lines after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script bash \n",
    "cd ~/s2ds/Data/\n",
    "wc -l 04_clientMessagesFiltered.txt\n",
    "wc -l 04_agentMessagesFiltered.txt\n",
    "wc -l 04_word2vecTrainingDataFiltered.txt\n",
    "wc -l 04_doc2vecTrainingDataFiltered.txt\n",
    "wc -l 04_doc2vecTrainingDataFiltered2.txt\n",
    "wc -l 05_clientMessagesFilteredfastText.txt\n",
    "wc -l 05_agentMessagesFilteredfastText.txt\n",
    "wc -l 05_fastTextConv.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
